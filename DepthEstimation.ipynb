{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DepthEstimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1NropGIR34ofz3f4jtHns3MYHpGsnfHWN",
      "authorship_tag": "ABX9TyNmEVkZmoBf37KafGpnbRgt"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZOUJfXpBXCF"
      },
      "outputs": [],
      "source": [
        "!curl -o data_depth_annotated.zip https://s3.eu-central-1.amazonaws.com/avg-kitti/data_depth_annotated.zip\n",
        "!unzip data_depth_annotated.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as dsets\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD, RMSprop\n",
        "import torch\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "from os import listdir\n",
        "from os.path import splitext\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "aWBvZtjTsWTo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class Encode(nn.Module):\n",
        "  def __init__(self, channels = (3,16,32,64,96,128,192)):\n",
        "    super(Encode, self).__init__()\n",
        "    self.en_blocks = nn.ModuleList([EncodeBlock(channels[i], channels[i+1]) for i in range(len(channels)-1)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    enc_features = []\n",
        "    for block in self.en_blocks:\n",
        "      x = block(x)\n",
        "      enc_features.append(x)\n",
        "    return enc_featuers\n",
        "\n",
        "class EncodeBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(EncodeBlock, self).__init__()\n",
        "    down_block1 = nn.Conv2d(in_channels, out_channels, kernel_size= 3, stride = 2, padding = 1 )\n",
        "    down_block2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1)\n",
        "    self.down_block = nn.Sequential(down_block1, nn.LeakyReLU(), down_block2, nn.LeakyReLU())\n",
        "  \n",
        "  def forward(self,x):\n",
        "    return self.down_block(x)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, channels = (16,32,64,96,128,192)):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.channels = channels\n",
        "    self.conv_dec = [convDisp(i) for i in channels]\n",
        "    self.disp = nn.Sigmoid()\n",
        "    self.deconv = nn.ConvTranspose2d(in_channels=8, out_channels=8, kernel_size=2, stride=2)\n",
        "\n",
        "  def convDisp(self, in_channels):\n",
        "    chnls = [in_channels] + [96,64,32,8]\n",
        "    layers = []\n",
        "    for i in range(len(chnls)-1):\n",
        "      layers += [nn.Conv2d(chnls[i], chnls[i+1], kernel_size = 3, stride = 1, padding = 1), nn.LeakyReLU()]\n",
        "    layers.pop()\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, enc_features):\n",
        "    feat = enc_features[-1]\n",
        "    disp_list = []\n",
        "    for i in range(len(enc_features),1, -1):\n",
        "      featb = self.conv_dec[i](feat)\n",
        "      disp_ = self.disp(featb)\n",
        "      featb = self.deconv(featb)\n",
        "      disp_list.append(disp_)\n",
        "      feat = torch.cat((enc_features[i-2], featb),1)\n",
        "    featb = self.conv_dec[0](feat)\n",
        "    disp_ = self.disp(featb)\n",
        "    disp_list.append(disp_)\n",
        "    return disp_list.reverse()\n",
        "  \n",
        "class DepthModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DepthModel, self).__init__()\n",
        "    self.encode_ = Encode()\n",
        "    self.decode_ = Decode()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # feat = self.encode_(x)\n",
        "    # disp = self.decode_(feat)\n",
        "    # return disp\n",
        "    return self.decode_(self.encode_(x))\n"
      ],
      "metadata": {
        "id": "XQBC8mwzsslD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}